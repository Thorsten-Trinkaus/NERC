{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc589c8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# First Look at the Datasets\n",
    "> Thorsten Trinkaus\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a8aaa1",
   "metadata": {},
   "source": [
    "---\n",
    "## Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a374e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a4c9c5",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20757ff",
   "metadata": {},
   "source": [
    "While OntoNotes and FIGER have their own Hugging Face datasets, Ultra Fine\n",
    "Entity Typing needs to be loaded manually from files. For more information see\n",
    "Choi, E., Levy, O., Choi, Y., & Zettlemoyer (2018). Ultra-Fine Entity Typing. In\n",
    "Proceedings of the ACL. Association for Computational Linguistics (https://www.cs.utexas.edu/~eunsol/html_pages/open_entity.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad89ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face Token\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# OntoNotes 5\n",
    "# revision because the dataset uses dataset scripts, \n",
    "# which datasets 4.0 does not support anymore.\n",
    "ds_onto = load_dataset(\n",
    "    \"tner/ontonotes5\", \n",
    "    revision=\"refs/convert/parquet\", \n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n",
    "# FIGER\n",
    "ds_figer = load_dataset(\"DGME/figer\", token=HF_TOKEN)\n",
    "\n",
    "# Ultra Fine Crowdsourced\n",
    "ds_fine_crowd = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": \"./ultra_fine/crowd/train.json\",\n",
    "        \"validation\": \"./ultra_fine/crowd/dev.json\",\n",
    "        \"test\": \"./ultra_fine/crowd/test.json\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ultra Fine Distantly Supervised\n",
    "# This dataset does not have a test split!\n",
    "ds_fine_ds = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": \"./ultra_fine/ds/el_train.json\",\n",
    "        \"validation\": \"./ultra_fine/ds/el_dev.json\",\n",
    "        \"test\": \"./ultra_fine/ds/el_dev.json\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860e7e6d",
   "metadata": {},
   "source": [
    "---\n",
    "## First Tests\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4bf9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_random(ds, n=5, split=\"train\"):\n",
    "    \"\"\"\n",
    "    Print n random samples from the dataset.\n",
    "\n",
    "    Args:\n",
    "        ds: The dataset from which to sample.\n",
    "        n: The number of samples (default is 5).\n",
    "        split: The dataset split to sample from (default is \"train\").\n",
    "    \"\"\"\n",
    "    for _ in range(n):\n",
    "        idx = random.randint(0, len(ds[split]) - 1)\n",
    "        sample = ds[split][idx]\n",
    "        print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2d77f6",
   "metadata": {},
   "source": [
    "### OntoNotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b052ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['US', 'Ambassador', 'Richard', 'Holbrooke', 'said', ',', 'President', 'Kostunica', 'is', 'to', 'be', 'congratulated', '.'], 'tags': [7, 0, 4, 5, 0, 0, 0, 4, 0, 0, 0, 0, 0]}\n",
      "{'tokens': ['Total', 'truck', 'production', 'fell', '22', '%', 'from', 'a', 'year', 'earlier', 'to', '315,546', 'units', '.'], 'tags': [0, 0, 0, 0, 13, 14, 0, 2, 3, 3, 0, 1, 0, 0]}\n",
      "{'tokens': ['Mr.', 'Levin', ',', 'former', 'head', 'of', 'EPA', \"'s\", 'regulatory', 'reform', 'staff', ',', 'adapted', 'this', 'from', 'his', 'November', 'column', 'for', 'the', 'Journal', 'of', 'the', 'Air', 'and', 'Waste', 'Management', 'Association', '.'], 'tags': [0, 4, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 11, 12, 12, 12, 12, 12, 12, 12, 12, 0]}\n",
      "{'tokens': ['Thanks', 'Wolf', '/.'], 'tags': [0, 4, 0]}\n",
      "{'tokens': ['So', 'how', 'are', 'they', 'getting', 'back', '?'], 'tags': [0, 0, 0, 0, 0, 0, 0]}\n",
      "Size of train split: 59924\n"
     ]
    }
   ],
   "source": [
    "print_random(ds_onto)\n",
    "print(\"Size of train split:\", len(ds_onto[\"train\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec0258f",
   "metadata": {},
   "source": [
    "How many entries of the train split do not contain any named entities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58eb760e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26804\n"
     ]
    }
   ],
   "source": [
    "tags_col = ds_onto[\"train\"][\"tags\"]\n",
    "zero_counter = sum(1 for tags in tags_col if tags and not any(tags))\n",
    "print(zero_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4859c5",
   "metadata": {},
   "source": [
    "### FIGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "839b2518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mention_span': 'Psary', 'left_context_token': ['It', 'lies', 'approximately', '3kmmi0', 'north', 'of'], 'right_context_token': [',', '8kmmi0on', 'north', 'of', 'Bedzin', ',', 'and', '19kmmi0on', 'north-east', 'of', 'the', 'regional', 'capital', 'Katowice', '.'], 'y_str': ['/location/city', '/location']}\n",
      "{'mention_span': 'Operation Barbarossa', 'left_context_token': ['The', 'Southern', 'Front', 'directed', 'military', 'operations', 'during', 'the', 'Soviet', 'occupation', 'of', 'Bessarabia', 'and', 'Northern', 'Bukovina', 'in', '1940', ',', 'and', 'then', 'was', 'formed', 'twice', 'after', 'the', 'June', '1941', 'German', 'invasion', ','], 'right_context_token': ['.'], 'y_str': ['/event/military_conflict', '/event']}\n",
      "{'mention_span': 'Pennsylvania', 'left_context_token': ['Daniel', '\"', 'Dan', '\"', 'Onorato', '(', 'born', 'February', '5', ',', '1961', ')', 'is', 'the', 'current', 'Chief', 'Executive', 'of', 'Allegheny', 'County', ','], 'right_context_token': ['.'], 'y_str': ['/government', '/government/government', '/organization', '/location/province', '/location']}\n",
      "{'mention_span': '1 .', 'left_context_token': ['Armin', 'Reutershahn', '(', 'born', '1', 'March', '1960', ')', 'is', 'a', 'German', 'football', 'coach', ',', 'he', 'is', 'currently', 'the', 'assistant', 'manager', 'of', 'Michael', 'Oenning', 'at', 'German', 'club'], 'right_context_token': [''], 'y_str': ['/organization/sports_team', '/organization']}\n",
      "{'mention_span': 'Battle of Bosworth', 'left_context_token': ['A', 'short', 'time', 'after', 'Henry', 'Tudor', \"'s\", 'victory', 'at', 'the'], 'right_context_token': ['on', '22', '&amp;', 'nbsp', ';', 'August', '1485', ',', 'his', 'army', 'suddenly', 'went', 'down', 'with', '\"', 'the', 'English', 'sweat', '\"', ',', 'which', 'contemporary', 'observers', 'described', 'as', 'something', 'new', '.'], 'y_str': ['/event/military_conflict', '/event']}\n",
      "Size of train split: 2690286\n"
     ]
    }
   ],
   "source": [
    "print_random(ds_figer)\n",
    "print(\"Size of train split:\", len(ds_figer[\"train\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21dcefa",
   "metadata": {},
   "source": [
    "### Ultra Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da8c8ae",
   "metadata": {},
   "source": [
    "Crowdsourced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19f11e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annot_id': 'wex/20110513/1/35/206:5:1', 'mention_span': 'The reservoirs', 'right_context_token': ['were', 'officially', 'opened', 'on', '15', 'December', '1931', 'by', 'Governor', 'of', 'Hong', 'Kong', 'William', 'Peel', ',', 'becoming', 'the', 'fourth', 'and', 'last', 'reservoir', 'group', 'ever', 'built', 'on', 'Hong', 'Kong', 'Island', ',', 'after', 'Pok', 'Fu', 'Lam', ',', 'Tai', 'Tam', 'and', 'Wong', 'Nai', 'Chung', '.'], 'y_str': ['point'], 'left_context_token': []}\n",
      "{'annot_id': 'APW_ENG_20001116.0360:19:659', 'mention_span': 'it', 'right_context_token': ['may', 'not', 'have', 'been', 'to', 'any', 'political', 'advantage', 'of', 'his', ',', \"''\", 'Peterson', 'said', '.', '``'], 'y_str': ['concept', 'idea', 'decision', 'choice', 'attempt', 'activity'], 'left_context_token': ['It', 'was', 'Bill', 'Clinton', 'who', 'opened', 'up', 'and', 'had', 'the', 'vision', 'for', 'moving', 'ahead', 'rather', 'aggressively', 'with', 'our', 'relationship', 'with', 'Vietnam', 'when', 'in', 'many', 'senses']}\n",
      "{'annot_id': 'XIN_ENG_20100122.0098:11:321', 'mention_span': 'she', 'right_context_token': ['said', '.'], 'y_str': ['woman', 'official', 'adult', 'female', 'engineer', 'spokesperson', 'womanhood', 'spokeswoman', 'charwoman', 'person'], 'left_context_token': ['\"', 'The', 'recommendation', 'of', 'the', 'Honeywell', 'white', 'paper', 'indicates', 'that', 'the', 'safety', 'analysis', 'of', 'aircraft', 'engines', 'installed', 'on', 'the', 'SA', 'Airlink', 'Jetstream', 'is', 'still', 'within', 'acceptable', 'risk', 'levels', ',', '\"']}\n",
      "{'annot_id': 'wex/20110513/4/82/748:0:1', 'mention_span': 'The Black Sea Shad -LRB- Alosa maeotica -RRB-', 'right_context_token': ['is', 'a', 'species', 'of', 'fish', 'in', 'the', 'Clupeidae', 'family', '.'], 'y_str': ['living_thing', 'vertebrate', 'organism', 'fish', 'object', 'animal'], 'left_context_token': []}\n",
      "{'annot_id': 'wex/20110513/3/5/86:43:1', 'mention_span': 'This embassy', 'right_context_token': ['was', 'ordered', 'by', 'the', 'new', 'Stewart', 'king', 'Robert', 'II', ',', 'three', 'days', 'after', 'his', 'accession', '.'], 'y_str': ['concept', 'idea', 'operation', 'thing', 'person', 'command', 'order', 'law'], 'left_context_token': []}\n",
      "Size of train split: 1998\n"
     ]
    }
   ],
   "source": [
    "print_random(ds_fine_crowd)\n",
    "print(\"Size of train split:\", len(ds_fine_crowd[\"train\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c856d5",
   "metadata": {},
   "source": [
    "Distantly Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11ce62c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'left_context_token': ['is', 'a', 'parasitic', 'nematode', 'worm', 'that', 'lives', 'in', 'the', 'swimbladders', 'of', 'eels', '-LRB-'], 'y_str': ['country', 'geography', 'location', 'island'], 'right_context_token': ['spp', '.', '-RRB-'], 'y': [1, 3756, 546, 51], 'y_type': [0, 0, 0, 0], 'goal_y_str': ['/location/country', '/geography', '/location', '/geography/island'], 'y_type_str': ['KB', 'KB', 'KB', 'KB'], 'goal_y': [5, 30, 0, 39], 'annot_id': '1154849', 'mention_span': 'Anguilla'}\n",
      "{'left_context_token': ['The', '2007-08', 'Philippine', 'Basketball', 'Association', '-LRB-', 'PBA', '-RRB-', 'Philippine', 'Cup', 'or', 'known', 'as', 'the', '2007-08', 'Smart', 'PBA', 'Philippine', 'Cup', 'for', 'sponsorship', 'reasons', ',', 'is', 'the', 'first', 'conference', 'of', 'the'], 'y_str': ['event'], 'right_context_token': ['PBA', 'season', '.'], 'y': [109], 'y_type': [0], 'goal_y_str': ['/event'], 'y_type_str': ['KB'], 'goal_y': [9], 'annot_id': '1865997', 'mention_span': '2007-08'}\n",
      "{'left_context_token': ['The', 'feast', 'of', 'Saint', 'Dominic', 'is', 'held', 'every', 'last', 'Sunday', 'of'], 'y_str': ['month'], 'right_context_token': ['.'], 'y': [14], 'y_type': [1], 'goal_y_str': None, 'y_type_str': ['WIKI'], 'goal_y': None, 'annot_id': '4196629:0:0', 'mention_span': 'August'}\n",
      "{'left_context_token': ['He', 'is', 'a', 'member', ',', 'and', 'former', 'chair', ',', 'of', 'the'], 'y_str': ['organization'], 'right_context_token': ['and', 'was', 'chosen', 'in', '2002', 'by', 'House', 'Minority', 'Leader', 'Nancy', 'Pelosi', 'to', 'serve', 'on', 'the', 'Democratic', 'Steering', 'Committee', '.'], 'y': [180], 'y_type': [0], 'goal_y_str': ['/organization'], 'y_type_str': ['KB'], 'goal_y': [2], 'annot_id': '634733', 'mention_span': 'Congressional Black Caucus'}\n",
      "{'left_context_token': ['The'], 'y_str': ['event'], 'right_context_token': ['Tampa', 'Bay', 'Buccaneers', 'season', 'began', 'with', 'the', 'team', 'trying', 'to', 'improve', 'on', 'an', '5-10-1', 'season', '.'], 'y': [109], 'y_type': [0], 'goal_y_str': ['/event'], 'y_type_str': ['KB'], 'goal_y': [9], 'annot_id': '1555910', 'mention_span': '1981'}\n",
      "Size of train split: 3091003\n"
     ]
    }
   ],
   "source": [
    "print_random(ds_fine_ds)\n",
    "print(\"Size of train split:\", len(ds_fine_ds[\"train\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fs_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
